{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import AsyncHTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_NUM = 10\n",
    "NUM_FROM_A_SITE = 20\n",
    "\n",
    "CLS_NAME = ['title', 'price', 'image', 'link']\n",
    "CLS_SH1 = [['div', 'sc-fcdeBU iVCsji'], ['div', 'sc-gmeYpB iBMbn'], '상품 이미지']\n",
    "CLS_SH2 = [['span', 'ProductItemV2_title__1KDby'], ['p', 'ProductItemV2_price__1a5yb mt3'], '이미지']\n",
    "CLS_NEW1 = [['div', 'basicList_title__3P9Q7'], ['span', 'price_num__2WUXn']]\n",
    "CLS_NEW2 = [['div', 'name'], ['strong', 'price-value'], ['img', 'search-product-wrap-img']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_bs(url):\n",
    "    session = AsyncHTMLSession()\n",
    "    resp = await session.get(url, verify=False)\n",
    "    await resp.html.arender(sleep = 1)\n",
    "    bs = BeautifulSoup(resp.html.raw_html, 'html.parser')\n",
    "    return bs\n",
    "\n",
    "\n",
    "async def get_shs(cls_names, url):\n",
    "    bs = await get_bs(url)\n",
    "    df = pd.DataFrame(columns=CLS_NAME)\n",
    "    for i, cls in enumerate(cls_names[:2]):\n",
    "        df[CLS_NAME[i]] = list(map(lambda x: x.get_text(), bs.find_all(*cls)[:NUM_FROM_A_SITE]))\n",
    "    df[CLS_NAME[2]] = list(map(lambda x: x['src'], bs.find_all('img', alt=cls_names[2])[:NUM_FROM_A_SITE]))\n",
    "    df[CLS_NAME[3]] = url\n",
    "    return df\n",
    "\n",
    "\n",
    "async def get_new_from_naver(cls_names, url):\n",
    "    bs = await get_bs(url)\n",
    "\n",
    "    df = pd.DataFrame(columns=CLS_NAME)\n",
    "    for i, cls in enumerate(cls_names[:2]):\n",
    "        df[CLS_NAME[i]] = list(map(lambda x: x.get_text(), bs.find_all(*cls)[:NUM_FROM_A_SITE]))\n",
    "\n",
    "    #############TODO\n",
    "    imgs = list(map(lambda x: x['src'], bs.find_all('a',alt=df[CLS_NAME[0]])))\n",
    "    if len(imgs) > NUM_FROM_A_SITE:\n",
    "        df[CLS_NAME[2]] = imgs[:NUM_FROM_A_SITE] ## 이렇게 나와야함\n",
    "    df[CLS_NAME[3]] = url\n",
    "    return df\n",
    "\n",
    "\n",
    "async def get_new_from_coupang(cls_names, url):\n",
    "    bs = await get_bs(url)\n",
    "    #page = requests.get(url)\n",
    "    #bs = BeautifulSoup(page.text, 'html.parser')\n",
    "    df = pd.DataFrame(columns=CLS_NAME)\n",
    "    for i, cls in enumerate(cls_names[:2]):\n",
    "        df[CLS_NAME[i]] = list(map(lambda x: x.get_text(), bs.find_all(*cls)[:NUM_FROM_A_SITE]))\n",
    "\n",
    "    df[CLS_NAME[2]] = list(map(lambda x: x['src'], bs.find_all(*cls_names[2])[:NUM_FROM_A_SITE]))\n",
    "    df[CLS_NAME[3]] = url\n",
    "    return df\n",
    "\n",
    "\n",
    "def string_price_to_num(str_price):\n",
    "    str_price = str_price.strip().strip(\"원\").split(\",\")\n",
    "    s = ''\n",
    "    for string in str_price:\n",
    "        s += string\n",
    "    return int(s)\n",
    "\n",
    "\n",
    "def alysis_dfs(df1, df2):\n",
    "    df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "    df['price'] = list(map(string_price_to_num, df['price']))  # 가격 숫자로\n",
    "    df = df.sort_values('price')[:TOTAL_NUM].reset_index()  # 가격 정렬\n",
    "    items = []\n",
    "    for sh in list(df.iterrows()):\n",
    "        items.append({\n",
    "            'title': sh[1]['title'],\n",
    "            'price': sh[1]['price'],\n",
    "            'image': sh[1]['image'],\n",
    "            'link': sh[1]['link']\n",
    "        })\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10808a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "        \n",
    "async def home(keyword):\n",
    "    start = time.time()\n",
    "    url_sh1 = f'https://m.bunjang.co.kr/search/products?q={keyword}'  # 번개장터\n",
    "    url_sh2 = f'https://m.joongna.com/search-list/product?searchword={keyword}'  # 중고나라\n",
    "    url_new1 = f'https://search.shopping.naver.com/search/all?query={keyword}'  # 네이버쇼핑\n",
    "    url_new2 = f'https://www.coupang.com/np/search?component=&q={keyword}'  # 쿠팡\n",
    "\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    ## 번개장터\n",
    "    sh_df = await get_shs(CLS_SH1, url_sh1)\n",
    "\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    ## 중고나라\n",
    "    sh_df_ = await get_shs(CLS_SH2, url_sh2)\n",
    "    \n",
    "    print(time.time() - start)\n",
    "    \n",
    "    sh_items = alysis_dfs(sh_df, sh_df_)\n",
    "    \n",
    "    ## 네이버쇼핑\n",
    "    ###########################TODO 이미지 안됨\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    new_df = await get_new_from_naver(CLS_NEW1, url_new1)\n",
    "\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    ## 쿠팡\n",
    "    ## TODO: request.get이 그냥 정지...?\n",
    "    new_df_ = await get_new_from_coupang(CLS_NEW2, url_new2)\n",
    "    \n",
    "    print(time.time() - start)\n",
    "    \n",
    "    new_items = alysis_dfs(new_df, new_df_)\n",
    "\n",
    "        \n",
    "    res = json.dumps({\n",
    "        \"new\":new_items,\n",
    "        \"sh\":sh_items\n",
    "        })\n",
    "    return res\n",
    "\n",
    "#print(await home('마이프로틴'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bddda6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/sample2/<keyword>')\n",
    "def main2(keyword):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    ## home이 asnyc 함수\n",
    "    res = loop.run_until_complete(home(keyword))\n",
    "    return res\n",
    "\n",
    "\n",
    "# @app.route('/sample/<keyword>')\n",
    "# async def main(keyword):\n",
    "#     url_sh1 = f'https://m.bunjang.co.kr/search/products?q={keyword}'  # 번개장터\n",
    "#     url_sh2 = f'https://m.joongna.com/search-list/product?searchword={keyword}'  # 중고나라\n",
    "#     url_new1 = f'https://search.shopping.naver.com/search/all?query={keyword}'  # 네이버쇼핑\n",
    "#     url_new2 = f'https://www.coupang.com/np/search?component=&q={keyword}'  # 쿠팡\n",
    "\n",
    "#     ## 번개장터\n",
    "#     sh_df = await get_shs(CLS_SH1, url_sh1)\n",
    "\n",
    "#     ## 중고나라\n",
    "#     sh_df_ = await get_shs(CLS_SH2, url_sh2)\n",
    "#     sh_items = alysis_dfs(sh_df, sh_df_)\n",
    "\n",
    "#     ## 네이버쇼핑\n",
    "#     ###########################TODO 이미지 안됨\n",
    "#     new_df = await get_new_from_naver(CLS_NEW1, url_new1)\n",
    "\n",
    "#     ## 쿠팡\n",
    "#     new_df_ = None #get_new_from_coupang(CLS_NEW2, url_new2)\n",
    "#     new_items = alysis_dfs(new_df, new_df_)\n",
    "\n",
    "#     res = json.dumps({\n",
    "#         \"new\":new_items,\n",
    "#         \"sh\":sh_items\n",
    "#         })\n",
    "#     return res\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
